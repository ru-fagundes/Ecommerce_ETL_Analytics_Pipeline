# üõí E-commerce ETL Analytics Pipeline

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![SQLite](https://img.shields.io/badge/SQLite-3-green.svg)
![Pandas](https://img.shields.io/badge/Pandas-Latest-orange.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)
![Status](https://img.shields.io/badge/Status-Production-success.svg)

> **Pipeline completo de ETL e Analytics para E-commerce com Data Warehouse dimensional, an√°lise de dados e dashboards interativos.**

---

## üìä M√©tricas do Projeto

```
üì¶ Dados Processados:  6.383 registros        üí∞ Faturamento Total:  R$ 9.629.301,57
üìà Ticket M√©dio:       R$ 4.814,65             üõçÔ∏è  Total de Pedidos:  2.000 pedidos
üë• Clientes Ativos:    483 clientes            üì¶ Produtos:           200 produtos
```

---

## üéØ Vis√£o Geral

Sistema de **Data Warehouse e Analytics** que transforma dados brutos de e-commerce em insights acion√°veis atrav√©s de um pipeline ETL automatizado.

### ‚ú® Caracter√≠sticas Principais

‚úÖ **ETL Automatizado** ‚Üí Extra√ß√£o, transforma√ß√£o e carga de dados  
‚úÖ **Star Schema** ‚Üí Modelagem dimensional otimizada para an√°lise  
‚úÖ **Data Quality** ‚Üí Pipeline de limpeza e valida√ß√£o de dados  
‚úÖ **Analytics Avan√ßado** ‚Üí KPIs, m√©tricas e visualiza√ß√µes interativas  
‚úÖ **Jupyter Notebooks** ‚Üí An√°lises explorat√≥rias e ad-hoc  
‚úÖ **Dashboard Interativo** ‚Üí Visualiza√ß√µes em tempo real com Streamlit  
‚úÖ **Gr√°ficos Est√°ticos** ‚Üí An√°lises profissionais com Matplotlib/Seaborn  

---

## üèóÔ∏è Arquitetura do Sistema

### Fluxo do Pipeline ETL

```mermaid
graph LR
    A[üìÇ CSV Files] --> B[üì• EXTRACT]
    B --> C[üîÑ STAGING]
    C --> D[‚öôÔ∏è TRANSFORM]
    D --> E[üóÑÔ∏è DATA WAREHOUSE]
    E --> F[üìä ANALYTICS]
    F --> G[üìà DASHBOARDS]
    
    style A fill:#e1f5ff
    style B fill:#fff4e1
    style C fill:#ffe1e1
    style D fill:#f0e1ff
    style E fill:#e1ffe1
    style F fill:#ffe1f5
    style G fill:#f5ffe1
```

### Modelo Dimensional (Star Schema)

```
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ dim_cliente ‚îÇ
                    ‚îÇ    üë•       ‚îÇ
                    ‚îÇ cliente_id  ‚îÇ
                    ‚îÇ nome        ‚îÇ
                    ‚îÇ email       ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ dim_produto ‚îÇ     ‚îÇ     ‚îÇ  dim_tempo  ‚îÇ
       ‚îÇ    üì¶       ‚îÇ     ‚îÇ     ‚îÇ     üìÖ      ‚îÇ
       ‚îÇ produto_id  ‚îÇ     ‚îÇ     ‚îÇ  tempo_id   ‚îÇ
       ‚îÇ categoria   ‚îÇ     ‚îÇ     ‚îÇ  data       ‚îÇ
       ‚îÇ preco       ‚îÇ     ‚îÇ     ‚îÇ  dia_semana ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ            ‚îÇ            ‚îÇ
              ‚îÇ       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  FATO   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ VENDAS  ‚îÇ
                      ‚îÇ   üí∞    ‚îÇ
                      ‚îÇ venda_id‚îÇ
                      ‚îÇquantidade‚îÇ
                      ‚îÇvalor_total‚îÇ
                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîÑ Pipeline ETL - Passo a Passo

### 1Ô∏è‚É£ **EXTRACT** - Extra√ß√£o de Dados

```python
# Leitura de m√∫ltiplos arquivos CSV
import pandas as pd

df_clientes = pd.read_csv('data/raw/clientes.csv')
df_produtos = pd.read_csv('data/raw/produtos.csv')
df_pedidos = pd.read_csv('data/raw/pedidos.csv')
df_itens = pd.read_csv('data/raw/item_pedido.csv')
```

### 2Ô∏è‚É£ **TRANSFORM** - Limpeza e Transforma√ß√£o

```python
# Pipeline de Data Quality
def limpar_dados(df):
    """Remove duplicatas e trata valores ausentes"""
    # Remover duplicatas
    df = df.drop_duplicates()
    
    # Validar dados obrigat√≥rios
    df = df.dropna(subset=['campo_obrigatorio'])
    
    # Converter tipos de dados
    df['data'] = pd.to_datetime(df['data'])
    df['valor'] = pd.to_numeric(df['valor'], errors='coerce')
    
    # Calcular m√©tricas
    df['valor_total'] = df['quantidade'] * df['preco_unitario']
    
    return df

# Agrega√ß√£o inteligente (evita duplicatas)
query = """
SELECT dt.dia_semana,
       COUNT(DISTINCT f.pedido_id) AS num_pedidos,
       SUM(f.valor_total) AS faturamento
FROM fato_vendas f
JOIN dim_tempo dt ON f.tempo_id = dt.tempo_id
GROUP BY dt.dia_semana
"""
```

### 3Ô∏è‚É£ **LOAD** - Carga no Data Warehouse

```python
import sqlite3

conn = sqlite3.connect('ecommerce_sqlite.db')

# Criar dimens√µes
dim_cliente.to_sql('dim_cliente', conn, if_exists='replace', index=False)
dim_produto.to_sql('dim_produto', conn, if_exists='replace', index=False)
dim_tempo.to_sql('dim_tempo', conn, if_exists='replace', index=False)

# Criar tabela fato
fato_vendas.to_sql('fato_vendas', conn, if_exists='replace', index=False)
```

### 4Ô∏è‚É£ **ANALYZE** - An√°lise e KPIs

```sql
-- Faturamento Mensal com Tend√™ncia
SELECT 
    strftime('%Y-%m', dt.data) AS mes,
    SUM(f.valor_total) AS faturamento,
    COUNT(DISTINCT f.pedido_id) AS num_pedidos,
    ROUND(AVG(f.valor_total), 2) AS ticket_medio
FROM fato_vendas f
JOIN dim_tempo dt ON f.tempo_id = dt.tempo_id
GROUP BY mes
ORDER BY mes;
```

---

## üöÄ In√≠cio R√°pido

### Instala√ß√£o

```bash
# 1. Clonar reposit√≥rio
git clone https://github.com/ru-fagundes/Ecommerce_ETL_Analytics_Pipeline.git
cd Ecommerce_ETL_Analytics_Pipeline

# 2. Criar ambiente virtual
python -m venv venv
venv\Scripts\activate  # Windows

# 3. Instalar depend√™ncias
pip install -r config/requirements.txt
```

### Execu√ß√£o

```bash
# 1. Executar pipeline ETL completo
python scripts/pipeline_carga.py

# Sa√≠da esperada:
# [2025-12-07 10:30:15] ‚úÖ Conectado ao database
# [2025-12-07 10:30:16] üì• Carregando staging...
# [2025-12-07 10:30:25] ‚úÖ Pipeline conclu√≠do com sucesso!

# 2. Gerar an√°lises e KPIs
python scripts/analise_dados.py

# Sa√≠da esperada:
# üìä KPIs PRINCIPAIS:
# üí∞ Faturamento Total: R$ 9.629.301,57
# üìà Ticket M√©dio: R$ 4.814,65

# 3. Abrir notebook de an√°lises
jupyter notebook notebooks/notebook_etl_analysis.ipynb

# 4. (Opcional) Extrair imagens das visualiza√ß√µes
python scripts/capturar_graficos.py
```

### üìì Como Usar o Notebook

**Op√ß√£o 1 - Execu√ß√£o Completa (Recomendado):**
```bash
# 1. Abrir notebook
jupyter notebook notebooks/notebook_etl_analysis.ipynb

# 2. No Jupyter, selecionar: Menu ‚Üí Kernel ‚Üí Restart & Run All
# ‚úÖ Todas as 36 c√©lulas ser√£o executadas em sequ√™ncia
# ‚è±Ô∏è Tempo estimado: 2-3 minutos
```

**Op√ß√£o 2 - Execu√ß√£o Seletiva:**
```python
# Execute c√©lulas espec√≠ficas:
# - C√©lulas 1-10: Setup e conex√£o
# - C√©lulas 11-17: KPIs b√°sicos (OBRIGAT√ìRIO antes das avan√ßadas)
# - C√©lulas 18-22: Limpeza de dados (OBRIGAT√ìRIO)
# - C√©lulas 23-34: An√°lises avan√ßadas (pode executar individualmente)
```

**Op√ß√£o 3 - Apenas Visualizar Resultados:**
```bash
# Se o notebook j√° foi executado anteriormente:
# 1. Abra o arquivo .ipynb no VS Code ou Jupyter
# 2. Role at√© as c√©lulas com gr√°ficos (11, 14, 17, 24, 26, 28, 30, 32, 34)
# 3. Visualize os outputs salvos
```

---

## üåê Dashboard Interativo (Streamlit)

### üöÄ Como Abrir o Dashboard no Navegador

**Pr√©-requisitos:**
```bash
# 1. Certifique-se que o pipeline ETL foi executado
python scripts/criar_tabelas_analiticas.py  # Criar estrutura
python scripts/pipeline_carga.py            # Popular dados

# Sa√≠da esperada:
# ‚úÖ dim_tempo: 880 registros
# ‚úÖ dim_cliente: 500 registros
# ‚úÖ dim_produto: 200 registros
# ‚úÖ fato_vendas: 3.183 registros
```

**Iniciar Dashboard:**
```bash
# Executar aplica√ß√£o Streamlit
streamlit run dashboard/app.py

# Sa√≠da no terminal:
#   You can now view your Streamlit app in your browser.
#
#   Local URL: http://localhost:8501
#   Network URL: http://192.168.x.x:8501
```

**Acessar no Navegador:**

1. **Op√ß√£o 1 - Autom√°tico**: O navegador abre automaticamente
2. **Op√ß√£o 2 - Manual**: Acesse `http://localhost:8501`
3. **Op√ß√£o 3 - Rede Local**: Use o Network URL para acessar de outros dispositivos

**Para Parar o Dashboard:**
```bash
# No terminal onde o Streamlit est√° rodando:
# Pressione Ctrl + C
```

### üìä Recursos do Dashboard Interativo

**Filtros Din√¢micos:**
- üìÖ **Per√≠odo**: Selecione intervalo de datas personalizado
- üì¶ **Categoria**: Filtre por categoria de produto
- üîÑ **Atualiza√ß√£o em Tempo Real**: Dados atualizados a cada intera√ß√£o

**Visualiza√ß√µes Dispon√≠veis:**

üéØ **P√°gina Principal - Vis√£o Geral:**
- KPIs principais (Cards com m√©tricas-chave)
- Gr√°fico de linha: Evolu√ß√£o temporal do faturamento
- Gr√°fico de pizza: Participa√ß√£o por categoria
- Gr√°fico de barras: Top produtos

üìà **An√°lises Avan√ßadas:**
- Heatmap de vendas por dia da semana
- An√°lise de comportamento de clientes
- Distribui√ß√µes estat√≠sticas interativas
- An√°lise de outliers com filtros

üí° **Recursos Interativos:**
- **Hover**: Passe o mouse sobre gr√°ficos para ver detalhes
- **Zoom**: Clique e arraste para ampliar √°reas espec√≠ficas
- **Download**: Exporte gr√°ficos em PNG (bot√£o no canto superior direito)
- **Filtros**: Sidebar com controles de data e categoria

### üõ†Ô∏è Tecnologias Utilizadas no Dashboard

```python
import streamlit as st        # Framework web interativo
import plotly.express as px   # Gr√°ficos interativos
import plotly.graph_objects   # Gr√°ficos customizados
import pandas as pd           # Manipula√ß√£o de dados
import sqlite3                # Conex√£o com banco de dados
```

**Vantagens do Streamlit:**
- ‚úÖ Zero configura√ß√£o de frontend
- ‚úÖ Gr√°ficos interativos nativos (Plotly)
- ‚úÖ Atualiza√ß√£o autom√°tica ao modificar c√≥digo
- ‚úÖ Deploy f√°cil (Streamlit Cloud, Heroku, etc.)
- ‚úÖ Widgets prontos (sliders, select boxes, date pickers)

### üé® Customiza√ß√µes do Dashboard

**Configura√ß√£o da P√°gina:**
```python
st.set_page_config(
    page_title="E-commerce Analytics Dashboard",
    page_icon="üõí",
    layout="wide",
    initial_sidebar_state="expanded"
)
```

**CSS Customizado:**
- Tema escuro/claro adaptativo
- Cards com gradientes
- Anima√ß√µes suaves
- Responsivo para mobile/tablet

### üì± Acesso Remoto (Rede Local)

**Compartilhar Dashboard na Rede Local:**

1. Execute o dashboard normalmente
2. Copie o **Network URL** do terminal (exemplo: `http://192.168.15.8:8501`)
3. Compartilhe este URL com outros dispositivos na mesma rede Wi-Fi
4. Acesse de tablets, smartphones ou outros computadores

**Exemplo de Uso:**
```bash
# No computador principal:
streamlit run dashboard/app.py

# Sa√≠da:
#   Network URL: http://192.168.15.8:8501

# Em outro dispositivo (mesma rede):
# Abra o navegador e acesse: http://192.168.15.8:8501
```

---

## üìä Visualiza√ß√µes e Dashboards

> ‚ö†Ô∏è **Para visualizar os gr√°ficos no README**:
> 
> 1. Abra o notebook: `notebooks/notebook_etl_analysis.ipynb`
> 2. Execute **todas as c√©lulas** (Menu ‚Üí Run ‚Üí Run All Cells)
> 3. Os gr√°ficos ser√£o exibidos automaticamente no notebook
> 4. **Para extrair imagens PNG**: Execute `python scripts/capturar_graficos.py`
>
> **Nota**: O script `capturar_graficos.py` extrai as imagens diretamente do notebook JSON (n√£o precisa executar c√©lulas primeiro se j√° foram executadas anteriormente)

### Dashboard Executivo

![Dashboard Executivo](docs/screenshots/dashboard_executivo.png)

**KPIs Principais:**
- üí∞ Faturamento Total
- üìà Ticket M√©dio  
- üõçÔ∏è Total de Pedidos
- üë• Clientes √önicos

**Gr√°ficos:**
- Evolu√ß√£o do Faturamento Mensal
- Participa√ß√£o de Receita por Categoria (Pizza)
- Top 5 Produtos Mais Vendidos
- Distribui√ß√£o de Pedidos por Faixa de Valor

---

### Distribui√ß√µes Estat√≠sticas e An√°lise de Outliers

![Distribui√ß√µes](docs/screenshots/distribuicoes_estatisticas.png)

**Dashboard com 6 An√°lises Estat√≠sticas:**
- **Histograma de Valor dos Pedidos** (com m√©dia e mediana)
- **Boxplot de Valor dos Pedidos** (detec√ß√£o de outliers, Q1, Q3, IQR)
- **Distribui√ß√£o de Itens por Pedido** (histograma com m√©dia)
- **Scatter: Valor vs Quantidade** (rela√ß√£o entre itens e valor total)
- **Violin Plot por Quartil de Itens** (distribui√ß√£o em cada quartil)
- **Identifica√ß√£o de Outliers** (scatter com limite superior marcado)

**Estat√≠sticas Fornecidas:**
- Desvio padr√£o e coeficiente de varia√ß√£o
- An√°lise de outliers (1.5 * IQR)
- Top 5 maiores outliers identificados

**Nota**: Esta visualiza√ß√£o √© gerada pela **c√©lula 32** do notebook

---


## üíª Exemplos de Queries SQL

### Top 10 Produtos Mais Vendidos

```sql
SELECT 
    p.nome AS produto,
    p.categoria,
    SUM(f.quantidade) AS total_vendido,
    SUM(f.valor_total) AS receita_total,
    ROUND(AVG(f.valor_unitario), 2) AS preco_medio
FROM fato_vendas f
JOIN dim_produto p ON f.produto_id = p.produto_id
GROUP BY p.produto_id, p.nome, p.categoria
ORDER BY total_vendido DESC
LIMIT 10;
```

**Resultado:**
```
produto              | categoria    | total_vendido | receita_total | preco_medio
---------------------|--------------|---------------|---------------|-------------
Produto 163 - Plus   | Eletr√¥nicos  | 90            | R$ 450.000    | R$ 5.000
Produto 32 - Plus    | Casa         | 85            | R$ 425.000    | R$ 5.000
Produto 173 - Plus   | Beleza       | 82            | R$ 410.000    | R$ 5.000
```

---

### An√°lise de Faturamento por Categoria

```sql
SELECT 
    p.categoria,
    COUNT(DISTINCT p.produto_id) AS num_produtos,
    SUM(f.valor_total) AS receita,
    ROUND(SUM(f.valor_total) * 100.0 / 
          (SELECT SUM(valor_total) FROM fato_vendas), 2) AS percentual
FROM fato_vendas f
JOIN dim_produto p ON f.produto_id = p.produto_id
GROUP BY p.categoria
ORDER BY receita DESC;
```

---

### Tend√™ncia de Vendas por Dia da Semana

```sql
SELECT 
    CASE dt.dia_semana
        WHEN 0 THEN 'Domingo'
        WHEN 1 THEN 'Segunda'
        WHEN 2 THEN 'Ter√ßa'
        WHEN 3 THEN 'Quarta'
        WHEN 4 THEN 'Quinta'
        WHEN 5 THEN 'Sexta'
        WHEN 6 THEN 'S√°bado'
    END AS dia,
    COUNT(DISTINCT f.pedido_id) AS num_pedidos,
    SUM(f.valor_total) AS faturamento,
    ROUND(AVG(f.valor_total), 2) AS ticket_medio
FROM fato_vendas f
JOIN dim_tempo dt ON f.tempo_id = dt.tempo_id
GROUP BY dt.dia_semana
ORDER BY dt.dia_semana;
```

---

## üîç Funcionalidades de Data Quality

### Pipeline de Limpeza Autom√°tico

```python
def verificar_qualidade_dados(conn):
    """
    An√°lise explorat√≥ria autom√°tica
    Detecta problemas de qualidade nos dados
    """
    problemas = []
    
    # 1. Verificar estrutura das tabelas
    for tabela in ['dim_cliente', 'dim_produto', 'dim_tempo', 'fato_vendas']:
        query = f"PRAGMA table_info({tabela})"
        schema = pd.read_sql(query, conn)
        print(f"‚úÖ Estrutura {tabela}: {len(schema)} colunas")
    
    # 2. Detectar duplicatas
    query = """
    SELECT data, dia_semana, COUNT(*) as qtd
    FROM dim_tempo
    GROUP BY data, dia_semana
    HAVING COUNT(*) > 1
    """
    duplicatas = pd.read_sql(query, conn)
    if len(duplicatas) > 0:
        problemas.append(f"‚ö†Ô∏è {len(duplicatas)} duplicatas em dim_tempo")
    
    # 3. Identificar valores nulos
    query = "SELECT COUNT(*) FROM fato_vendas WHERE valor_total IS NULL"
    nulls = pd.read_sql(query, conn).iloc[0, 0]
    if nulls > 0:
        problemas.append(f"‚ö†Ô∏è {nulls} valores nulos em fato_vendas")
    
    return problemas
```

### Bins Din√¢micos para Distribui√ß√µes

```python
import numpy as np

def criar_bins_dinamicos(df, coluna):
    """Cria bins adaptativos baseados no valor m√°ximo"""
    max_valor = df[coluna].max()
    
    if max_valor <= 5000:
        bins = [0, 1000, 2000, 3000, 4000, np.inf]
        labels = ['0-1K', '1K-2K', '2K-3K', '3K-4K', '4K+']
    elif max_valor <= 10000:
        bins = [0, 2000, 4000, 6000, 8000, np.inf]
        labels = ['0-2K', '2K-4K', '4K-6K', '6K-8K', '8K+']
    else:
        bins = [0, 10000, 20000, 50000, np.inf]
        labels = ['0-10K', '10K-20K', '20K-50K', '50K+']
    
    return bins, labels

# Uso
bins, labels = criar_bins_dinamicos(df_vendas, 'valor_pedido')
df_vendas['faixa'] = pd.cut(df_vendas['valor_pedido'], bins=bins, labels=labels)
```

---

## üìÅ Estrutura do Projeto

```
ecommerce-etl-pipeline/
‚îÇ
‚îú‚îÄ‚îÄ üìÇ config/
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt          # Depend√™ncias Python
‚îÇ
‚îú‚îÄ‚îÄ üìÇ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                      # CSVs originais
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ clientes.csv
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ produtos.csv
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pedidos.csv
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ item_pedido.csv
‚îÇ   ‚îî‚îÄ‚îÄ processed/                # Dados processados
‚îÇ
‚îú‚îÄ‚îÄ üìÇ dashboard/
‚îÇ   ‚îî‚îÄ‚îÄ app.py                    # Aplica√ß√£o Streamlit
‚îÇ
‚îú‚îÄ‚îÄ üìÇ docs/
‚îÇ   ‚îú‚îÄ‚îÄ RELATORIO_FINAL.md        # Relat√≥rio t√©cnico completo
‚îÇ   ‚îú‚îÄ‚îÄ GUIA_SCREENSHOTS.md       # Guia de captura de imagens
‚îÇ   ‚îú‚îÄ‚îÄ ATUALIZACOES_DEZ2025.md   # Changelog de melhorias
‚îÇ   ‚îî‚îÄ‚îÄ screenshots/              # Imagens das visualiza√ß√µes
‚îÇ
‚îú‚îÄ‚îÄ üìÇ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ notebook_etl_analysis.ipynb  # An√°lises interativas (36 c√©lulas)
‚îÇ
‚îú‚îÄ‚îÄ üìÇ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ pipeline_carga.py         # Pipeline ETL principal
‚îÇ   ‚îú‚îÄ‚îÄ sqlite_etl.py             # ETL espec√≠fico SQLite
‚îÇ   ‚îú‚îÄ‚îÄ analise_dados.py          # Gera√ß√£o de KPIs e relat√≥rios
‚îÇ   ‚îî‚îÄ‚îÄ verificar_database.py     # Diagn√≥stico e valida√ß√£o
‚îÇ
‚îú‚îÄ‚îÄ üìÇ sql/
‚îÇ   ‚îú‚îÄ‚îÄ ddl/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ddl_transacional.sql  # Schema fonte
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ddl_analitico.sql     # Schema DW
‚îÇ   ‚îî‚îÄ‚îÄ queries/
‚îÇ       ‚îú‚îÄ‚îÄ analytical_queries.sql # Queries de an√°lise
‚îÇ       ‚îî‚îÄ‚îÄ quality_checks.sql     # Valida√ß√µes de qualidade
‚îÇ
‚îú‚îÄ‚îÄ üóÑÔ∏è ecommerce_sqlite.db        # Database SQLite (9 tabelas)
‚îî‚îÄ‚îÄ üìÑ README.md                   # Este arquivo
```

---

## üõ†Ô∏è Tecnologias Utilizadas

| Categoria | Tecnologias |
|-----------|-------------|
| **Linguagem** | Python 3.8+ |
| **Database** | SQLite 3 |
| **ETL & Data** | Pandas, NumPy |
| **Visualiza√ß√£o** | Matplotlib, Seaborn, Plotly |
| **Dashboard Interativo** | Streamlit 1.28+ |
| **Notebooks** | Jupyter Notebook |
| **Controle de Vers√£o** | Git, GitHub |

---

### Comandos √öteis

```bash
# Verificar instala√ß√£o do Streamlit
streamlit --version

# Limpar cache do Streamlit
streamlit cache clear

# Ver configura√ß√µes do Streamlit
streamlit config show

# Executar em modo de debug
streamlit run dashboard/app.py --logger.level=debug

# Desabilitar monitoramento de arquivos (mais r√°pido)
streamlit run dashboard/app.py --server.fileWatcherType none
```

---

## üìö Documenta√ß√£o Completa

### Guias Dispon√≠veis

- üìò [**RELATORIO_FINAL.md**](docs/RELATORIO_FINAL.md) - Relat√≥rio t√©cnico completo com todas as melhorias implementadas
- üì∏ [**GUIA_SCREENSHOTS.md**](docs/GUIA_SCREENSHOTS.md) - Tutorial para captura de visualiza√ß√µes
- üÜï [**ATUALIZACOES_DEZ2025.md**](docs/ATUALIZACOES_DEZ2025.md) - Changelog de melhorias v2.1
- üìä [**INDICE_DOCUMENTACAO.md**](docs/INDICE_DOCUMENTACAO.md) - √çndice completo da documenta√ß√£o

---

## üéØ Casos de Uso

### 1. An√°lise de Vendas
- Identificar produtos mais vendidos
- Analisar tend√™ncias temporais
- Calcular m√©tricas de performance

### 2. Segmenta√ß√£o de Clientes
- Top clientes por faturamento
- An√°lise de frequ√™ncia de compra
- Ticket m√©dio por cliente

### 3. Otimiza√ß√£o de Estoque
- Produtos com baixa rotatividade
- Sazonalidade de vendas
- Previs√£o de demanda

### 4. Business Intelligence
- Dashboards executivos
- Relat√≥rios automatizados
- Alertas de performance

---

## üöÄ Melhorias Futuras

- [‚úì] **Dashboard Streamlit interativo** ‚úÖ **IMPLEMENTADO**
- [ ] API REST para consultas
- [ ] Integra√ß√£o com Power BI
- [ ] Machine Learning para previs√µes
- [ ] Pipeline em tempo real (Kafka/Airflow)
- [ ] Testes automatizados (pytest)
- [ ] CI/CD com GitHub Actions
- [ ] Containeriza√ß√£o (Docker)

---

## üìß Contato

**Rubia Fagundes**  
üìß Email: [rubiafagundes_ds@outlook.com](mailto:seu-email@example.com)  
üíº LinkedIn: [linkedin.com/in/rubiafagundes](https://linkedin.com/in/seu-perfil)  
üê± GitHub: [@ru-fagundes](https://github.com/ru-fagundes)

---

## üìÑ Licen√ßa

Este projeto est√° sob a licen√ßa MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

---

## ‚≠ê Agradecimentos

Projeto desenvolvido como portf√≥lio de **Engenharia de Dados** demonstrando habilidades em:
- Pipeline ETL
- Modelagem Dimensional
- Data Quality
- Analytics com SQL
- Visualiza√ß√£o de Dados
- Dashboards Interativos (Streamlit)
- Python para Dados

---

<div align="center">

**‚≠ê Se este projeto foi √∫til, considere dar uma estrela no reposit√≥rio!**

[![GitHub Stars](https://img.shields.io/github/stars/ru-fagundes/Ecommerce_ETL_Analytics_Pipeline?style=social)](https://github.com/ru-fagundes/Ecommerce_ETL_Analytics_Pipeline/stargazers)
[![GitHub Forks](https://img.shields.io/github/forks/ru-fagundes/Ecommerce_ETL_Analytics_Pipeline?style=social)](https://github.com/ru-fagundes/Ecommerce_ETL_Analytics_Pipeline/network/members)

</div>

---

*√öltima atualiza√ß√£o: 09/12/2025 - v2.2 - Dashboard Interativo Streamlit*
